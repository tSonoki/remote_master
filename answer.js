import { ONNXInferenceEngine } from './onnxInference.js';

const signalingSocket = new WebSocket("ws://localhost:8080");
const autorunSocket = new WebSocket("ws://127.0.0.1:8081");
let peerConnection;
let remoteDataChannel = null;
let iceCandidateQueue = []; // ãƒªãƒ¢ãƒ¼ãƒˆSDPè¨­å®šå‰ã®ICEå€™è£œã‚’ä¿å­˜ã™ã‚‹ã‚­ãƒ¥ãƒ¼
let stream = null;
const streamCaptureBtn = document.getElementById("stream-capture");
const cameraSelect = document.getElementById("camera-select");

// ONNX Inference Engine
let onnxEngine = null;
let detectionCanvas = null;
let detectionContext = null;
let largeDetectionCanvas = null;
let largeDetectionContext = null;
let isInferenceEnabled = false; // æ¨è«–ã®æœ‰åŠ¹/ç„¡åŠ¹çŠ¶æ…‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚ªãƒ•ï¼‰

// ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤ºæ›´æ–°
function updateInferenceStatus(status) {
  const statusElement = document.getElementById("inference-status");
  if (statusElement) {
    statusElement.textContent = `çŠ¶æ…‹: ${status}`;
    statusElement.className = isInferenceEnabled ? "status-enabled" : "status-disabled";
  }
}


// Canvasè¡¨ç¤ºåˆ¶å¾¡ï¼ˆè»½é‡åŒ–ã®ãŸã‚ï¼‰
let isCanvasVisible = false;
function toggleCanvas() {
  const canvas = document.getElementById("large-detection-canvas");
  const checkbox = document.getElementById("canvas-toggle");
  isCanvasVisible = checkbox.checked;
  canvas.style.display = isCanvasVisible ? "block" : "none";
  console.log(`Detection Canvas ${isCanvasVisible ? "è¡¨ç¤º" : "éè¡¨ç¤º"}`);
}

// å®‰å…¨ã‚·ã‚¹ãƒ†ãƒ å‡¦ç†é–¢æ•°
function handleEmergencyStop(data) {
  console.warn('ğŸš¨ EMERGENCY STOP RECEIVED:', data);
  
  // ãƒˆãƒ©ã‚¯ã‚¿åˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã«åœæ­¢ä¿¡å·ã‚’é€ä¿¡
  if (autorunSocket && autorunSocket.readyState === WebSocket.OPEN) {
    const emergencyStopCommand = {
      type: "emergency_stop",
      timestamp: data.timestamp,
      reason: data.reason,
      action: "immediate_stop"
    };
    
    try {
      autorunSocket.send(JSON.stringify(emergencyStopCommand));
      console.log('Emergency stop command sent to tractor control system');
    } catch (error) {
      console.error('Failed to send emergency stop to tractor:', error);
    }
  } else {
    console.error('Tractor control connection not available');
  }
  
  // ãƒ­ãƒ¼ã‚«ãƒ«UIã‚‚æ›´æ–°
  showEmergencyAlert("äººã‚’æ¤œçŸ¥ã—ã¾ã—ãŸï¼ãƒˆãƒ©ã‚¯ã‚¿ã‚’ç·Šæ€¥åœæ­¢ã—ã¾ã™ã€‚");
}

function handleWarningLight(data) {
  console.log(`Warning light ${data.action}:`, data);
  
  // ãƒ‘ãƒˆãƒ©ã‚¤ãƒˆåˆ¶å¾¡ã‚·ã‚¹ãƒ†ãƒ ã«ä¿¡å·ã‚’é€ä¿¡
  if (autorunSocket && autorunSocket.readyState === WebSocket.OPEN) {
    const warningLightCommand = {
      type: "warning_light_control",
      action: data.action, // "on" or "off"
      timestamp: data.timestamp,
      pattern: "emergency" // ç‚¹æ»…ãƒ‘ã‚¿ãƒ¼ãƒ³
    };
    
    try {
      autorunSocket.send(JSON.stringify(warningLightCommand));
      console.log(`Warning light ${data.action} command sent`);
    } catch (error) {
      console.error('Failed to send warning light command:', error);
    }
  }
  
  // ãƒ­ãƒ¼ã‚«ãƒ«UIã‚‚æ›´æ–°
  updateWarningLightStatus(data.action === "on");
}

function showEmergencyAlert(message) {
  // ç·Šæ€¥ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ãƒ–ãƒ©ã‚¦ã‚¶ã«è¡¨ç¤º
  const alertDiv = document.createElement('div');
  alertDiv.style.cssText = `
    position: fixed;
    top: 20px;
    left: 50%;
    transform: translateX(-50%);
    background: #ff0000;
    color: white;
    padding: 20px;
    border-radius: 10px;
    z-index: 9999;
    font-size: 18px;
    font-weight: bold;
    box-shadow: 0 4px 8px rgba(0,0,0,0.3);
    animation: pulse 1s infinite;
  `;
  alertDiv.textContent = message;
  
  document.body.appendChild(alertDiv);
  
  // 10ç§’å¾Œã«è‡ªå‹•å‰Šé™¤
  setTimeout(() => {
    if (alertDiv.parentNode) {
      alertDiv.parentNode.removeChild(alertDiv);
    }
  }, 10000);
}

function updateWarningLightStatus(isOn) {
  const statusElement = document.getElementById("warning-light-status");
  if (statusElement) {
    statusElement.textContent = `ãƒ‘ãƒˆãƒ©ã‚¤ãƒˆ: ${isOn ? "ç‚¹ç¯ä¸­" : "æ¶ˆç¯"}`;
    statusElement.className = isOn ? "warning-on" : "warning-off";
  }
}

function handleDetectionData(data) {
  console.log('Received detection data from offer side:', data);
  
  // Offerå´ã‹ã‚‰ã®æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†
  // è‡ªå‹•ãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½ã®ãŸã‚ã«äººã®æ¤œå‡ºæ•°ã‚’ç›£è¦–
  const personCount = data.c || 0; // count
  const timestamp = data.ts || Date.now();
  
  // æ¤œå‡ºãƒ‡ãƒ¼ã‚¿ã‚’Offerå´ã«é€ä¿¡ã—ã¦å®‰å…¨ã‚·ã‚¹ãƒ†ãƒ ã®çŠ¶æ…‹ã‚’åŒæœŸ
  if (remoteDataChannel && remoteDataChannel.readyState === "open") {
    try {
      const syncMessage = {
        type: "detection_sync",
        timestamp: timestamp,
        personCount: personCount,
        side: "answer"
      };
      
      remoteDataChannel.send(JSON.stringify(syncMessage));
      console.log(`Detection sync sent: ${personCount} persons detected`);
    } catch (error) {
      console.warn("Failed to send detection sync:", error.message);
    }
  }
}

// ã‚°ãƒ­ãƒ¼ãƒãƒ«é–¢æ•°ã¨ã—ã¦ç™»éŒ²
window.toggleCanvas = toggleCanvas;

// Initialize ONNX model with WebGPU acceleration
async function initONNXModel() {
  try {
    onnxEngine = new ONNXInferenceEngine();
    const success = await onnxEngine.initializeModel();
    
    if (success) {
      // Get detection canvas overlay (small one)
      detectionCanvas = document.getElementById("detection-canvas");
      if (detectionCanvas) {
        detectionContext = detectionCanvas.getContext("2d");
      }

      // Get large detection canvas
      largeDetectionCanvas = document.getElementById("large-detection-canvas");
      if (largeDetectionCanvas) {
        largeDetectionContext = largeDetectionCanvas.getContext("2d");
        console.log("ONNX inference engine initialized on answer side");
        return true;
      } else {
        console.error("Large detection canvas not found in DOM");
        return false;
      }
    } else {
      console.error("Failed to initialize ONNX inference engine");
      return false;
    }
  } catch (error) {
    console.error("Error initializing ONNX inference engine:", error);
    return false;
  }
}

// Stream video to large canvas
function streamToCanvas(videoElement, canvas, context) {
  if (!canvas || !context || !videoElement || videoElement.videoWidth === 0)
    return;

  // Draw video frame to large canvas (1920x1080)
  context.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
}

// Draw bounding boxes on large canvas (1920x1080)
function drawBoundingBoxesOnLargeCanvas(detections) {
  if (!largeDetectionCanvas || !largeDetectionContext) {
    console.error("Large canvas not available");
    return;
  }

  // Note: We don't clear the canvas here because we want to keep the video stream

  if (detections.length === 0) {
    return;
  }

  // Scale factors from 640x640 model input to 1920x1080 canvas
  const scaleX = 1920 / 640;
  const scaleY = 1080 / 640;

  // COCO class names
  const classNames = [
    "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light",
    "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow",
    "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee",
    "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard",
    "tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
    "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch",
    "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone",
    "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear",
    "hair drier", "toothbrush",
  ];

  detections.forEach((detection, idx) => {
    const bbox = detection.bbox;

    // Scale coordinates from 640x640 to 1920x1080
    const x = bbox.x * scaleX;
    const y = bbox.y * scaleY;
    const width = bbox.width * scaleX;
    const height = bbox.height * scaleY;

    // Choose color for this detection
    const hue = (idx * 137.5) % 360;
    const boxColor = `hsl(${hue}, 100%, 50%)`;

    // Draw bounding box
    largeDetectionContext.strokeStyle = boxColor;
    largeDetectionContext.lineWidth = 6; // Thicker lines for large canvas
    largeDetectionContext.strokeRect(x, y, width, height);

    // Prepare label text
    const className =
      classNames[detection.classId] || `Class ${detection.classId}`;
    const confidence = (detection.confidence * 100).toFixed(1);
    const label = `${className} ${confidence}%`;

    // Set font and measure text (larger for large canvas)
    largeDetectionContext.font = "bold 32px Arial";
    const textMetrics = largeDetectionContext.measureText(label);
    const textWidth = textMetrics.width;
    const textHeight = 40;

    // Calculate label position
    const labelX = Math.max(0, x);
    const labelY = Math.max(textHeight, y);

    // Draw label background
    largeDetectionContext.fillStyle = boxColor;
    largeDetectionContext.fillRect(
      labelX,
      labelY - textHeight,
      textWidth + 16,
      textHeight + 8
    );

    // Draw label text
    largeDetectionContext.fillStyle = "white";
    largeDetectionContext.fillText(label, labelX + 8, labelY - 8);
  });
}

// Run ONNX inference using the inference engine
async function runInference(videoElement) {
  if (!onnxEngine || !videoElement || videoElement.videoWidth === 0) return null;
  
  return await onnxEngine.runInference(videoElement, "answer");
}

// Performance monitoring variables
let inferenceCount = 0;
let totalInferenceTime = 0;
let dynamicInterval = 100; // Start with 100ms (10 FPS) - è»½é‡åŒ–
let isInferenceBusy = false; // æ¨è«–å‡¦ç†ä¸­ãƒ•ãƒ©ã‚°

// Start continuous inference on video stream with adaptive FPS
function startVideoInference(videoElement) {
  async function inferenceLoop() {
    if (videoElement && videoElement.videoWidth > 0 && largeDetectionCanvas && largeDetectionContext) {
      const startTime = performance.now();

      // Stream video to large canvas first (è¡¨ç¤ºæ™‚ã®ã¿å®Ÿè¡Œã§è»½é‡åŒ–)
      if (isCanvasVisible) {
        streamToCanvas(videoElement, largeDetectionCanvas, largeDetectionContext);
      }

      // Only run inference if enabled and not already busy
      if (isInferenceEnabled && !isInferenceBusy) {
        isInferenceBusy = true;
        try {
          const results = await runInference(videoElement);
          if (results && results.detections) {
            // Draw bounding boxes on large canvas over the video streamï¼ˆè¡¨ç¤ºæ™‚ã®ã¿ï¼‰
            if (isCanvasVisible) {
              drawBoundingBoxesOnLargeCanvas(results.detections);
            }

            // Send results through WebRTC data channel (åŠ¹ç‡åŒ–ã¨ãƒ‡ãƒ¼ã‚¿å‰Šæ¸›)
            if (remoteDataChannel && remoteDataChannel.readyState === "open") {
              // äººæ¤œå‡ºã®ã¿ã«çµã£ã¦é€ä¿¡ï¼ˆclassId === 0ï¼‰
              const personDetections = results.detections.filter(d => d.classId === 0);
              
              if (personDetections.length > 0) {
                const optimizedDetections = personDetections.map(d => ([
                  Math.round(d.bbox.x), Math.round(d.bbox.y), 
                  Math.round(d.bbox.width), Math.round(d.bbox.height),
                  Math.round(d.confidence * 1000) // 0-1000ã®æ•´æ•°å€¤
                ]));
                
                // ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§é€ä¿¡
                const compactMessage = {
                  t: "answer_detect", // typeçŸ­ç¸®
                  ts: Date.now(),
                  d: optimizedDetections, // detections
                  c: personDetections.length // count
                };
                
                try {
                  remoteDataChannel.send(JSON.stringify(compactMessage));
                } catch (sendError) {
                  console.warn("Failed to send detection data:", sendError.message);
                }
              }
            }
          }
        } finally {
          isInferenceBusy = false;
        }
      }

      const endTime = performance.now();
      const inferenceTime = endTime - startTime;

      // Update performance metrics
      inferenceCount++;
      totalInferenceTime += inferenceTime;

      if (inferenceCount % 30 === 0) {
        // Log every 30 inferences
        const avgInferenceTime = totalInferenceTime / 30;

        // Adaptive interval adjustment (ã‚ˆã‚Šä¿å®ˆçš„)
        if (avgInferenceTime < 50) {
          dynamicInterval = Math.max(50, dynamicInterval - 5); // Up to 20 FPS
        } else if (avgInferenceTime < 100) {
          dynamicInterval = Math.max(100, dynamicInterval - 2); // Up to 10 FPS
        } else if (avgInferenceTime > 200) {
          dynamicInterval = Math.min(500, dynamicInterval + 25); // Down to 2 FPS
        }
        
        // ONNXã‚¨ãƒ³ã‚¸ãƒ³ã®æ¨è«–é–“éš”ã‚‚èª¿æ•´
        if (onnxEngine) {
          onnxEngine.adjustInferenceInterval(avgInferenceTime);
        }

        totalInferenceTime = 0;
        inferenceCount = 0;
      }
    }

    // Schedule next inference (æ¨è«–ã‚ªãƒ•æ™‚ã¯è»½é‡ãƒã‚§ãƒƒã‚¯)
    if (isInferenceEnabled) {
      setTimeout(inferenceLoop, dynamicInterval);
    } else {
      setTimeout(inferenceLoop, 100); // æ¨è«–ã‚ªãƒ•æ™‚ã¯è»½é‡ãƒã‚§ãƒƒã‚¯
    }
  }

  // Start the inference loop
  inferenceLoop();
}

let mr1000aReceiveInfo = {
  lat: 0,
  lon: 0,
  gnssQuality: 0,
  gnssSpeed: 0,
  heading: 0,
  headingError: 0,
  lateralError: 0,
  steerAngle: 0,
  realSteerAngle: 0,
  stopStatus: 0,
};

signalingSocket.onmessage = async (event) => {
  const { type, payload } = JSON.parse(event.data);

  if (type === "offer") {
    peerConnection = new RTCPeerConnection({
      iceServers: [{ urls: "stun:10.100.0.35:3478" }],
    });

    await peerConnection.setRemoteDescription(
      new RTCSessionDescription({ type: "offer", sdp: payload.sdp })
    );

    stream.getTracks().forEach((track) => {
      peerConnection.addTrack(track, stream);
    });

    peerConnection.ondatachannel = (event) => {
      remoteDataChannel = event.channel;

      remoteDataChannel.onopen = () => {
        console.log("DataChannel is open");
        setInterval(() => {
          if (remoteDataChannel != null) {
            remoteDataChannel.send(
              JSON.stringify({
                type: "outputAutorunInfo",
                payload: mr1000aReceiveInfo,
              })
            );
          }
        }, 33); // ç´„30Hz
      };

      remoteDataChannel.onmessage = (event) => {
        const data = JSON.parse(event.data);
        switch (data.type) {
          case "inputAutorunInfo":
            if (autorunSocket != null) {
              const remoteDrivingData = data;
              autorunSocket.send(
                JSON.stringify({
                  type: "inputAutorunInfo",
                  payload: { inputInfo: remoteDrivingData },
                })
              );
            }
            break;
          case "emergency_stop":
            handleEmergencyStop(data);
            break;
          case "warning_light":
            handleWarningLight(data);
            break;
          case "offer_detect":
            // Offerå´ã‹ã‚‰ã®æ¤œçŸ¥çµæœï¼ˆã‚³ãƒ³ãƒ‘ã‚¯ãƒˆå½¢å¼ï¼‰
            handleDetectionData(data);
            break;
          case "videoQualityChange":
            console.log("Received video quality change request:", data.payload); // å—ä¿¡ãƒ­ã‚°ã‚’è¿½åŠ 
            const videoSender = peerConnection.getSenders().find(
              (sender) => sender.track && sender.track.kind === "video"
            );
            if (videoSender) {
              const params = videoSender.getParameters();
              if (params.encodings && params.encodings.length > 0) {
                // data.payload.bitrate ã‚’å‚ç…§ã™ã‚‹ã‚ˆã†ã«ä¿®æ­£
                params.encodings[0].maxBitrate = data.payload.bitrate;
                videoSender.setParameters(params)
                  .then(() => {
                    console.log(`Video bitrate successfully changed to: ${data.payload.bitrate}`);
                  })
                  .catch(e => {
                    console.error("Failed to set video bitrate:", e);
                  });
              }
            }
            break;
          case "offerInferenceResults":
            console.log(
              "Received inference results from offer side:",
              data.payload
            );
            break;
        }
      };
    };

    peerConnection.onicecandidate = (event) => {
      if (event.candidate) {
        signalingSocket.send(
          JSON.stringify({
            type: "ice-answer",
            payload: { candidate: event.candidate },
          })
        );
      }
    };

    while (iceCandidateQueue.length > 0) {
      const candidate = iceCandidateQueue.shift();
      await peerConnection.addIceCandidate(candidate);
    }

    const answer = await peerConnection.createAnswer();
    await peerConnection.setLocalDescription(answer);

    signalingSocket.send(
      JSON.stringify({ type: "answer", payload: { sdp: answer.sdp } })
    );
  } else if (type === "ice-offer") {
    const candidate = new RTCIceCandidate(payload.candidate);

    if (peerConnection && peerConnection.remoteDescription) {
      await peerConnection.addIceCandidate(candidate);
    } else {
      iceCandidateQueue.push(candidate);
    }
  }
};

signalingSocket.onopen = () => {
  signalingSocket.send(
    JSON.stringify({ type: "register-answer", payload: { id: "answer" } })
  );
};

autorunSocket.onopen = () => {
  autorunSocket.send(JSON.stringify({ type: "remote-control" }));
};

autorunSocket.onmessage = (event) => {
  const nodeData = JSON.parse(event.data);
  if (nodeData.type === "autorun-output-data") {
    const { outputAutorunInfo } = nodeData.payload;
    mr1000aReceiveInfo = outputAutorunInfo;
  }
};

function populateCameras() {
  if (!("mediaDevices" in navigator)) return;
  navigator.mediaDevices.enumerateDevices().then((mediaDevices) => {
    while (cameraSelect.options.length > 0) {
      cameraSelect.remove(0);
    }
    const defaultOption = document.createElement("option");
    defaultOption.id = "default";
    defaultOption.textContent = "Default Camera";
    cameraSelect.appendChild(defaultOption);

    const videoInputDevices = mediaDevices.filter(
      (mediaDevice) => mediaDevice.kind === "videoinput"
    );
    if (videoInputDevices.length > 0) {
      cameraSelect.disabled = false;
    }
    videoInputDevices.forEach((videoInputDevice, index) => {
      if (!videoInputDevice.deviceId) {
        return;
      }
      const option = document.createElement("option");
      option.id = videoInputDevice.deviceId;
      option.textContent = videoInputDevice.label || `Camera ${index + 1}`;
      option.selected = deviceId == option.id;
      cameraSelect.appendChild(option);
    });
  });
}

window.addEventListener("DOMContentLoaded", populateCameras);
if ("mediaDevices" in navigator) {
  navigator.mediaDevices.addEventListener("devicechange", populateCameras);
}

let deviceId = "default";
cameraSelect.onchange = (_) => {
  deviceId = cameraSelect.selectedOptions[0].id;
};

streamCaptureBtn.addEventListener("click", async () => {
  stream = await navigator.mediaDevices.getUserMedia({
    video: {
      width: Number(document.getElementById("video-width").value),
      height: Number(document.getElementById("video-height").value),
      frameRate: Number(document.getElementById("video-rate").value),
      deviceId: String(deviceId),
    },
  });
  const videoElement = document.getElementById("local-video");
  videoElement.srcObject = stream;

  videoElement.addEventListener("loadeddata", async () => {
    await new Promise(resolve => setTimeout(resolve, 100));
    
    const modelInitialized = await initONNXModel();
    if (modelInitialized && largeDetectionCanvas && largeDetectionContext) {
      startVideoInference(videoElement);
    }
  });

  const inferenceOnRadio = document.getElementById("inference-on");
  const inferenceOffRadio = document.getElementById("inference-off");
  
  inferenceOnRadio.addEventListener("change", () => {
    if (inferenceOnRadio.checked) {
      isInferenceEnabled = true;
      console.log("Answer side inference enabled");
      updateInferenceStatus("æ¨è«–æœ‰åŠ¹");
    }
  });
  
  inferenceOffRadio.addEventListener("change", () => {
    if (inferenceOffRadio.checked) {
      isInferenceEnabled = false;
      console.log("Answer side inference disabled");
      updateInferenceStatus("æ¨è«–ç„¡åŠ¹");
      // ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
      if (onnxEngine) {
        onnxEngine.cleanupMemory();
      }
    }
  });
  
  // åˆæœŸçŠ¶æ…‹è¡¨ç¤º
  updateInferenceStatus("æ¨è«–ç„¡åŠ¹");
});

// ===== ã“ã“ã‹ã‚‰è©³ç´°WebRTCçµ±è¨ˆãƒ­ã‚°æ©Ÿèƒ½ (Answerå´) =====
const webrtcStatsLogs = [];

// çµ±ä¸€ã•ã‚ŒãŸãƒ­ã‚°ã‚¹ã‚­ãƒ¼ãƒã‚’ä½œæˆã™ã‚‹é–¢æ•°ï¼ˆAnswerå´ç‰ˆï¼‰
function createUnifiedLogEntry() {
  const now = new Date();
  const isoTimestamp = now.toISOString();
  
  return {
    // åŸºæœ¬æƒ…å ±ï¼ˆå…±é€šï¼‰
    timestamp: isoTimestamp,
    time_formatted: now.toLocaleTimeString('ja-JP'),
    side: 'answer',
    session_id: peerConnection ? peerConnection._sessionId || 'unknown' : 'no_connection',
    
    // æ¥ç¶šçŠ¶æ…‹ï¼ˆå…±é€šï¼‰
    connection_state: peerConnection ? peerConnection.connectionState : 'unknown',
    ice_connection_state: peerConnection ? peerConnection.iceConnectionState : 'unknown',
    ice_gathering_state: peerConnection ? peerConnection.iceGatheringState : 'unknown',
    
    // ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³çŠ¶æ…‹ï¼ˆå…±é€šï¼‰
    inference_enabled: isInferenceEnabled,
    canvas_visible: isCanvasVisible,
    
    // Videoå“è³ªï¼ˆAnswerå´ï¼šé€ä¿¡çµ±è¨ˆï¼‰
    frame_width: 0,
    frame_height: 0,
    frames_per_second: 0,
    frames_received: 0, // Offerå´ã§ä½¿ç”¨
    frames_decoded: 0, // Offerå´ã§ä½¿ç”¨
    frames_dropped: 0, // Offerå´ã§ä½¿ç”¨
    frames_sent: 0,
    frames_encoded: 0,
    key_frames_decoded: 0, // Offerå´ã§ä½¿ç”¨
    key_frames_encoded: 0,
    
    // å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹
    actual_fps_received: 0, // Offerå´ã§ä½¿ç”¨
    actual_fps_decoded: 0, // Offerå´ã§ä½¿ç”¨
    actual_fps_sent: 0,
    actual_fps_encoded: 0,
    avg_decode_time_ms: 0, // Offerå´ã§ä½¿ç”¨
    avg_encode_time_ms: 0,
    total_decode_time_ms: 0, // Offerå´ã§ä½¿ç”¨
    total_encode_time_ms: 0,
    
    // ã‚¸ãƒƒã‚¿ãƒ¼ãƒãƒƒãƒ•ã‚¡ï¼ˆä¸»ã«Offerå´ï¼‰
    jitter_buffer_delay_ms: 0,
    jitter_buffer_emitted_count: 0,
    avg_jitter_buffer_delay_ms: 0,
    
    // ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯çµ±è¨ˆï¼ˆå…±é€šï¼‰
    jitter_ms: 0,
    rtt_ms: 0,
    packets_received: 0, // Offerå´ã§ä½¿ç”¨
    packets_sent: 0,
    packets_lost: 0,
    bytes_received: 0, // Offerå´ã§ä½¿ç”¨
    bytes_sent: 0,
    header_bytes_received: 0, // Offerå´ã§ä½¿ç”¨
    packets_per_second: 0,
    bitrate_kbps: 0,
    target_bitrate: 0,
    available_outgoing_bitrate: 0,
    
    // ã‚¨ãƒ©ãƒ¼çµ±è¨ˆï¼ˆå…±é€šï¼‰
    fir_count: 0,
    pli_count: 0,
    nack_count: 0,
    retransmitted_packets_sent: 0,
    retransmitted_bytes_sent: 0,
    
    // ONNXæ¨è«–çµ±è¨ˆï¼ˆå…±é€šï¼‰
    avg_inference_time_ms: 0,
    total_inferences: 0,
    skipped_frames_inference: 0,
    skip_rate_percent: 0,
    min_inference_interval_ms: 0,
    
    // æ¤œå‡ºçµæœçµ±è¨ˆï¼ˆå…±é€šï¼‰
    detections_count: 0,
    detections_person_count: 0,
    max_confidence: 0,
    avg_confidence: 0
  };
}

// Answerå´ç”¨çµ±è¨ˆä¿å­˜æ©Ÿèƒ½
function saveAnswerWebRTCStats() {
  const now = new Date();
  const jst = new Date(now.getTime() + 9 * 60 * 60 * 1000);
  const pad = n => n.toString().padStart(2, "0");
  const ts = `${jst.getUTCFullYear()}-${pad(jst.getUTCMonth() + 1)}-${pad(jst.getUTCDate())}_${pad(jst.getUTCHours())}-${pad(jst.getUTCMinutes())}-${pad(jst.getUTCSeconds())}`;

  if (webrtcStatsLogs.length > 0) {
    const headers = Object.keys(webrtcStatsLogs[0]);
    const csv = [
      headers.join(","),
      ...webrtcStatsLogs.map(row => headers.map(h => row[h] ?? "").join(","))
    ].join("\n");
    
    const blob = new Blob([csv], { type: "text/csv;charset=utf-8;" });
    const url = URL.createObjectURL(blob);
    const a = document.createElement("a");
    a.href = url;
    a.download = `answer_webrtc_unified_stats_${ts}.csv`;
    a.click();
    URL.revokeObjectURL(url);
    console.log(`çµ±ä¸€WebRTCçµ±è¨ˆã‚’ä¿å­˜: ${webrtcStatsLogs.length}ã‚¨ãƒ³ãƒˆãƒª (${ts})`);
  } else {
    console.log("ä¿å­˜ã™ã‚‹çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“");
  }
}

function clearAnswerWebRTCStats() {
  webrtcStatsLogs.length = 0;
  console.log("WebRTCçµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ");
}

setInterval(async function debugRTCStats() {
  if (!peerConnection) return;
  const stats = await peerConnection.getStats();

  let logRow = {
    timestamp: new Date().toLocaleTimeString('ja-JP'),
    roundTripTime: null,
    targetBitrate: null, // targetBitrate ã‚’è¿½åŠ 
    totalPacketSendDelay: null,
    '[totalPacketSendDelay/packetsSent_in_ms]': null,
    totalEncodeTime: null,
    '[totalEncodeTime/framesEncoded_in_ms]': null,
    packetsSent: null,
    bytesSent: null,
    framesEncoded: null,
    '[framesEncoded/s]': null,
    frameWidth: null,
    frameHeight: null,
    framesPerSecond: null,
  };

  let prevFramesEncoded = null;
  let prevTimestamp = null;

  stats.forEach((report) => {
    if (report.type === "candidate-pair" && report.state === "succeeded") {
      logRow.roundTripTime = report.currentRoundTripTime ?? report.roundTripTime ?? null;
    }

    if (report.type === "outbound-rtp" && report.kind === "video") {
      logRow.targetBitrate = report.targetBitrate ?? null; // targetBitrate ã‚’å–å¾—
      logRow.packetsSent = report.packetsSent ?? null;
      logRow.bytesSent = report.bytesSent ?? null;
      logRow.totalEncodeTime = report.totalEncodeTime ?? null;
      logRow.framesEncoded = report.framesEncoded ?? null;
      logRow.totalPacketSendDelay = report.totalPacketSendDelay ?? null;

      if (report.totalEncodeTime !== undefined && report.framesEncoded > 0) {
        logRow['[totalEncodeTime/framesEncoded_in_ms]'] =
          ((report.totalEncodeTime / report.framesEncoded) * 1000).toFixed(3);
      }

      if (report.totalPacketSendDelay !== undefined && report.packetsSent > 0) {
        logRow['[totalPacketSendDelay/packetsSent_in_ms]'] =
          ((report.totalPacketSendDelay / report.packetsSent) * 1000).toFixed(6);
      }

      // framesEncoded/s ã®è¨ˆç®—
      if (prevFramesEncoded !== null && prevTimestamp !== null && report.framesEncoded) {
        const timeDiff = (report.timestamp - prevTimestamp) / 1000; // in seconds
        const frameDiff = report.framesEncoded - prevFramesEncoded;
        if (timeDiff > 0) {
            logRow['[framesEncoded/s]'] = (frameDiff / timeDiff).toFixed(2);
        }
      }
      prevFramesEncoded = report.framesEncoded;
      prevTimestamp = report.timestamp;
    }

    if (report.type === "media-source" && report.kind === "video") {
      logRow.frameWidth = report.width ?? logRow.frameWidth;
      logRow.frameHeight = report.height ?? logRow.frameHeight;
      logRow.framesPerSecond = report.framesPerSecond ?? logRow.framesPerSecond;
    }
  });

  // çµ±ä¸€ã‚¹ã‚­ãƒ¼ãƒã§ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’ä½œæˆ
  let logEntry = createUnifiedLogEntry();
  
  // ONNXæ¨è«–çµ±è¨ˆã‚’è¿½åŠ 
  if (onnxEngine) {
    const perfStats = onnxEngine.getPerformanceStats();
    logEntry.avg_inference_time_ms = perfStats.averageTime || 0;
    logEntry.total_inferences = perfStats.totalInferences || 0;
    logEntry.skipped_frames_inference = perfStats.skippedFrames || 0;
    logEntry.skip_rate_percent = perfStats.skipRate || 0;
    logEntry.min_inference_interval_ms = onnxEngine.minInferenceInterval || 0;
  }

  // æ—¢å­˜ã®ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã‚’çµ±ä¸€ã‚¹ã‚­ãƒ¼ãƒã«ãƒãƒƒãƒ”ãƒ³ã‚°
  logEntry.target_bitrate = logRow.targetBitrate || 0;
  logEntry.packets_sent = logRow.packetsSent || 0;
  logEntry.bytes_sent = logRow.bytesSent || 0;
  logEntry.total_encode_time_ms = logRow.totalEncodeTime ? 
    parseFloat((logRow.totalEncodeTime * 1000).toFixed(3)) : 0;  
  logEntry.frames_encoded = logRow.framesEncoded || 0;
  logEntry.rtt_ms = logRow.roundTripTime ? 
    parseFloat((logRow.roundTripTime * 1000).toFixed(3)) : 0;
  logEntry.avg_encode_time_ms = logRow['[totalEncodeTime/framesEncoded_in_ms]'] ? 
    parseFloat(logRow['[totalEncodeTime/framesEncoded_in_ms]']) : 0;
  logEntry.actual_fps_encoded = logRow['[framesEncoded/s]'] ? 
    parseFloat(logRow['[framesEncoded/s]']) : 0;
  logEntry.frame_width = logRow.frameWidth || 0;
  logEntry.frame_height = logRow.frameHeight || 0;
  logEntry.frames_per_second = logRow.framesPerSecond || 0;
  
  // çµ±ä¸€ãƒ­ã‚°ã«ä¿å­˜
  webrtcStatsLogs.push(logEntry);
  
  // ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡åˆ¶é™
  if (webrtcStatsLogs.length > 1000) {
    webrtcStatsLogs.splice(0, webrtcStatsLogs.length - 1000);
  }
}, 1000);

// CSVä¿å­˜
function saveDelayLogsAsCSV() {
  if (delayLogs.length === 0) return;

  const headers = Object.keys(delayLogs[0]);
  const csvContent = [
    headers.join(","),
    ...delayLogs.map(log => headers.map(h => log[h] ?? "").join(","))
  ].join("\n");

  const blob = new Blob([csvContent], { type: "text/csv;charset=utf-8;" });
  const url = URL.createObjectURL(blob);
  const a = document.createElement("a");
  a.href = url;

  const now = new Date();
  const jst = new Date(now.getTime() + 9 * 60 * 60 * 1000); // æ—¥æœ¬æ™‚é–“ (JST) ã«å¤‰æ›
  const pad = n => n.toString().padStart(2, "0");
  const ts = `${jst.getUTCFullYear()}-${pad(jst.getUTCMonth() + 1)}-${pad(jst.getUTCDate())}_${pad(jst.getUTCHours())}-${pad(jst.getUTCMinutes())}-${pad(jst.getUTCSeconds())}`;

  a.download = `answer_webrtc_delay_log_${ts}.csv`;
  a.click();
  URL.revokeObjectURL(url);
}

document.getElementById("save-delay-log").addEventListener("click", saveAnswerWebRTCStats);
document.getElementById("clear-stats").addEventListener("click", clearAnswerWebRTCStats);
// ===== é…å»¶ãƒ­ã‚°æ©Ÿèƒ½ã“ã“ã¾ã§ =====
